{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-ai-ml\n",
    "!pip install mltable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from math import sqrt\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import mlflow\n",
    "import mltable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Enter details of your AML workspace\n",
    "subscription_id = \"4a571c1c-a483-4a43-9930-490479d70db0\"\n",
    "resource_group = \"Learn_MLOps\"\n",
    "workspace = \"MLOs_WS\"\n",
    "\n",
    "# get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_data_asset = ml_client.data.get(\n",
    "    name=\"processed_weather_data_port_of_Turku\",version='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uri = workspace.get_mlflow_tracking_uri()\n",
    "uri = ml_client.workspaces.get(ml_client.workspace_name).mlflow_tracking_uri\n",
    "mlflow.set_tracking_uri(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Location</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind_speed_kmph</th>\n",
       "      <th>Wind_bearing_degrees</th>\n",
       "      <th>Visibility_km</th>\n",
       "      <th>Pressure_millibars</th>\n",
       "      <th>Current_weather_condition</th>\n",
       "      <th>Future_weather_condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-04-01 04:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>8.755555556</td>\n",
       "      <td>0.83</td>\n",
       "      <td>11.0446</td>\n",
       "      <td>259</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>1016.51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-04-01 05:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>9.222222222</td>\n",
       "      <td>0.85</td>\n",
       "      <td>13.9587</td>\n",
       "      <td>258</td>\n",
       "      <td>14.9569</td>\n",
       "      <td>1016.66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-04-01 06:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>7.733333333</td>\n",
       "      <td>0.95</td>\n",
       "      <td>12.3648</td>\n",
       "      <td>259</td>\n",
       "      <td>9.982</td>\n",
       "      <td>1016.72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-04-01 07:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>8.772222222</td>\n",
       "      <td>0.89</td>\n",
       "      <td>14.1519</td>\n",
       "      <td>260</td>\n",
       "      <td>9.982</td>\n",
       "      <td>1016.84</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-04-01 08:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>10.82222222</td>\n",
       "      <td>0.82</td>\n",
       "      <td>11.3183</td>\n",
       "      <td>259</td>\n",
       "      <td>9.982</td>\n",
       "      <td>1017.37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Timestamp                Location Temperature_C Humidity  \\\n",
       "0  2006-04-01 04:00:00+02:00  Port of Turku, Finland   8.755555556     0.83   \n",
       "1  2006-04-01 05:00:00+02:00  Port of Turku, Finland   9.222222222     0.85   \n",
       "2  2006-04-01 06:00:00+02:00  Port of Turku, Finland   7.733333333     0.95   \n",
       "3  2006-04-01 07:00:00+02:00  Port of Turku, Finland   8.772222222     0.89   \n",
       "4  2006-04-01 08:00:00+02:00  Port of Turku, Finland   10.82222222     0.82   \n",
       "\n",
       "  Wind_speed_kmph Wind_bearing_degrees Visibility_km Pressure_millibars  \\\n",
       "0         11.0446                  259       15.8263            1016.51   \n",
       "1         13.9587                  258       14.9569            1016.66   \n",
       "2         12.3648                  259         9.982            1016.72   \n",
       "3         14.1519                  260         9.982            1016.84   \n",
       "4         11.3183                  259         9.982            1017.37   \n",
       "\n",
       "  Current_weather_condition Future_weather_condition  \n",
       "0                         1                        1  \n",
       "1                         1                        1  \n",
       "2                         1                        1  \n",
       "3                         1                        1  \n",
       "4                         1                        1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a path or folder or pattern\n",
    "# path = {\n",
    "#     'file': 'azureml://subscriptions/4a571c1c-a483-4a43-9930-490479d70db0/resourcegroups/Learn_MLops/workspaces/MLOs_WS/datastores/workspaceblobstore/paths/LocalUpload/39e72abce50cc70e7c0f6e2cdab79e0b/Dataset/weather_dataset_processed.csv'}\n",
    "\n",
    "path = {'file':f'{registered_data_asset.path}weather_dataset_processed.csv'}\n",
    "# create an mltable from paths\n",
    "tbl = mltable.from_delimited_files(paths=[path])\n",
    "\n",
    "# materialize to pandas\n",
    "df = tbl.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Location</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind_speed_kmph</th>\n",
       "      <th>Wind_bearing_degrees</th>\n",
       "      <th>Visibility_km</th>\n",
       "      <th>Pressure_millibars</th>\n",
       "      <th>Current_weather_condition</th>\n",
       "      <th>Future_weather_condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-04-01 04:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>8.755555556</td>\n",
       "      <td>0.83</td>\n",
       "      <td>11.0446</td>\n",
       "      <td>259</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>1016.51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-04-01 05:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>9.222222222</td>\n",
       "      <td>0.85</td>\n",
       "      <td>13.9587</td>\n",
       "      <td>258</td>\n",
       "      <td>14.9569</td>\n",
       "      <td>1016.66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-04-01 06:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>7.733333333</td>\n",
       "      <td>0.95</td>\n",
       "      <td>12.3648</td>\n",
       "      <td>259</td>\n",
       "      <td>9.982</td>\n",
       "      <td>1016.72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-04-01 07:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>8.772222222</td>\n",
       "      <td>0.89</td>\n",
       "      <td>14.1519</td>\n",
       "      <td>260</td>\n",
       "      <td>9.982</td>\n",
       "      <td>1016.84</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-04-01 08:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>10.82222222</td>\n",
       "      <td>0.82</td>\n",
       "      <td>11.3183</td>\n",
       "      <td>259</td>\n",
       "      <td>9.982</td>\n",
       "      <td>1017.37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Timestamp                Location Temperature_C Humidity  \\\n",
       "0  2006-04-01 04:00:00+02:00  Port of Turku, Finland   8.755555556     0.83   \n",
       "1  2006-04-01 05:00:00+02:00  Port of Turku, Finland   9.222222222     0.85   \n",
       "2  2006-04-01 06:00:00+02:00  Port of Turku, Finland   7.733333333     0.95   \n",
       "3  2006-04-01 07:00:00+02:00  Port of Turku, Finland   8.772222222     0.89   \n",
       "4  2006-04-01 08:00:00+02:00  Port of Turku, Finland   10.82222222     0.82   \n",
       "\n",
       "  Wind_speed_kmph Wind_bearing_degrees Visibility_km Pressure_millibars  \\\n",
       "0         11.0446                  259       15.8263            1016.51   \n",
       "1         13.9587                  258       14.9569            1016.66   \n",
       "2         12.3648                  259         9.982            1016.72   \n",
       "3         14.1519                  260         9.982            1016.84   \n",
       "4         11.3183                  259         9.982            1017.37   \n",
       "\n",
       "  Current_weather_condition Future_weather_condition  \n",
       "0                         1                        1  \n",
       "1                         1                        1  \n",
       "2                         1                        1  \n",
       "3                         1                        1  \n",
       "4                         1                        1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting Pre-Processed data into Training and Validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set is used later to evaluate model performance post training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = df.iloc[:77160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77160, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = df.drop(df_training.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19289, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registering Training and Validation data to the datastore on the workspace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.to_csv('Data/training_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation.to_csv('Data/validation_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "# Supported paths include:\n",
    "# local: './<path>'\n",
    "# blob:  'https://<account_name>.blob.core.windows.net/<container_name>/<path>'\n",
    "# ADLS gen2: 'abfss://<file_system>@<account_name>.dfs.core.windows.net/<path>/'\n",
    "# Datastore: 'azureml://datastores/<data_store_name>/paths/<path>'\n",
    "\n",
    "my_path = './Data/'\n",
    "\n",
    "my_data = Data(\n",
    "    path=my_path,\n",
    "    type=AssetTypes.MLTABLE,\n",
    "    description='processed weather data',\n",
    "    name=\"processed_weather_data_port_of_Turku\",\n",
    "    version='2'\n",
    ")\n",
    "\n",
    "ml_client.data.create_or_update(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data ingestion step - Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = {'file':'azureml://subscriptions/4a571c1c-a483-4a43-9930-490479d70db0/resourcegroups/Learn_MLops/workspaces/MLOs_WS/datastores/workspaceblobstore/paths/LocalUpload/2ee72d117bfcc8b45d53e4ba082b4d2a/Data/training_data.csv'}\n",
    "# create an mltable from paths\n",
    "tbl = mltable.from_delimited_files(paths=[path])\n",
    "\n",
    "# materialize to pandas\n",
    "df = tbl.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Location</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind_speed_kmph</th>\n",
       "      <th>Wind_bearing_degrees</th>\n",
       "      <th>Visibility_km</th>\n",
       "      <th>Pressure_millibars</th>\n",
       "      <th>Current_weather_condition</th>\n",
       "      <th>Future_weather_condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-04-01 02:00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>8.755556</td>\n",
       "      <td>0.83</td>\n",
       "      <td>11.0446</td>\n",
       "      <td>259</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>1016.51</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-04-01 03:00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>9.222222</td>\n",
       "      <td>0.85</td>\n",
       "      <td>13.9587</td>\n",
       "      <td>258</td>\n",
       "      <td>14.9569</td>\n",
       "      <td>1016.66</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-04-01 04:00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>7.733333</td>\n",
       "      <td>0.95</td>\n",
       "      <td>12.3648</td>\n",
       "      <td>259</td>\n",
       "      <td>9.9820</td>\n",
       "      <td>1016.72</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-04-01 05:00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>8.772222</td>\n",
       "      <td>0.89</td>\n",
       "      <td>14.1519</td>\n",
       "      <td>260</td>\n",
       "      <td>9.9820</td>\n",
       "      <td>1016.84</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-04-01 06:00:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>10.822222</td>\n",
       "      <td>0.82</td>\n",
       "      <td>11.3183</td>\n",
       "      <td>259</td>\n",
       "      <td>9.9820</td>\n",
       "      <td>1017.37</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp                Location  Temperature_C  Humidity  \\\n",
       "0 2006-04-01 02:00:00  Port of Turku, Finland       8.755556      0.83   \n",
       "1 2006-04-01 03:00:00  Port of Turku, Finland       9.222222      0.85   \n",
       "2 2006-04-01 04:00:00  Port of Turku, Finland       7.733333      0.95   \n",
       "3 2006-04-01 05:00:00  Port of Turku, Finland       8.772222      0.89   \n",
       "4 2006-04-01 06:00:00  Port of Turku, Finland      10.822222      0.82   \n",
       "\n",
       "   Wind_speed_kmph  Wind_bearing_degrees  Visibility_km  Pressure_millibars  \\\n",
       "0          11.0446                   259        15.8263             1016.51   \n",
       "1          13.9587                   258        14.9569             1016.66   \n",
       "2          12.3648                   259         9.9820             1016.72   \n",
       "3          14.1519                   260         9.9820             1016.84   \n",
       "4          11.3183                   259         9.9820             1017.37   \n",
       "\n",
       "   Current_weather_condition  Future_weather_condition  \n",
       "0                       True                      True  \n",
       "1                       True                      True  \n",
       "2                       True                      True  \n",
       "3                       True                      True  \n",
       "4                       True                      True  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77160, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['Temperature_C', 'Humidity', 'Wind_speed_kmph', 'Wind_bearing_degrees', 'Visibility_km', 'Pressure_millibars', 'Current_weather_condition']].values\n",
    "y = df['Future_weather_condition'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.3.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-learn) (1.9.3)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-learn) (1.23.4)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=1.1.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-learn) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Training dataset into Train and Test set for ML training\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and Testing Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='', creation_time=1671868697927, experiment_id='1d2c9fe3-9b67-4311-930c-a740a1d3d8f2', last_update_time=None, lifecycle_stage='active', name='mlflow-support-vector-machine', tags={}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# myexperiment = Experiment(workspace, \"support-vector-machine\")\n",
    "mlflow.set_experiment(\"mlflow-support-vector-machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.svm import SVC\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a run in Azureml and mlflow experiments\n",
    "# run = myexperiment.start_logging()\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.sklearn.autolog()\n",
    "    \n",
    "    mlflow.log_text(\"dataset name\", registered_data_asset.name)\n",
    "    mlflow.log_text(\"dataset Version\", '2')\n",
    "    \n",
    "    # svc_grid = GridSearchCV(svc, parameters)\n",
    "    # svc_grid.fit(X_train, y_train)\n",
    "\n",
    "    svc = SVC(C=1, kernel='rbf')\n",
    "    svc.fit(X_train, y_train)\n",
    "    \n",
    "    predicted_svc = svc.predict(X_test)\n",
    "    acc = accuracy_score(y_test, predicted_svc)\n",
    "    \n",
    "    fscore = f1_score(y_test, predicted_svc, average=\"macro\")\n",
    "    precision = precision_score(y_test, predicted_svc, average=\"macro\")\n",
    "    recall = recall_score(y_test, predicted_svc, average=\"macro\")\n",
    "    \n",
    "    mlflow.log_metric(\"Test_accuracy\", acc)\n",
    "    mlflow.log_metric(\"Test_Precision\", precision)\n",
    "    mlflow.log_metric(\"Test_Recall\", recall)\n",
    "    mlflow.log_metric(\"Test_F-Score\", fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='', creation_time=1671913622865, experiment_id='a629928c-9024-4a56-8e65-50dea1125044', last_update_time=None, lifecycle_stage='active', name='mlflow-random-forest-classifier', tags={}>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# myexperiment = Experiment(workspace, \"random-forest-classifier\")\n",
    "mlflow.set_experiment(\"mlflow-random-forest-classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=10, random_state=0, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize runs in Azureml and mlflow\n",
    "# run = myexperiment.start_logging()\n",
    "with mlflow.start_run() as run:\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    # Log dataset used \n",
    "    mlflow.log_text(\"dataset name\", registered_data_asset.name)\n",
    "    mlflow.log_text(\"dataset Version\", '2')\n",
    "    \n",
    "    \n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    predicted_rf = rf.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, predicted_rf)\n",
    "    fscore = f1_score(y_test, predicted_rf, average=\"macro\")\n",
    "    precision = precision_score(y_test, predicted_rf, average=\"macro\")\n",
    "    recall = recall_score(y_test, predicted_rf, average=\"macro\")\n",
    "    \n",
    "    metric ={\"Test_accuracy\": acc,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F-Score\": fscore}\n",
    "    mlflow.log_metrics(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Packaging Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pickle file or onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn\n",
    "!pip install -U skl2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The maximum opset needed by this model is only 1.\n"
     ]
    }
   ],
   "source": [
    "# Convert into SVC model into ONNX format file\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "initial_type = [('float_input', FloatTensorType([None, 6]))]\n",
    "onx = convert_sklearn(svc, initial_types=initial_type)\n",
    "with open(\"outputs/svc.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'classes_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [32], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskl2onnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FloatTensorType\n\u001b[1;32m      4\u001b[0m initial_type \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat_input\u001b[39m\u001b[38;5;124m'\u001b[39m, FloatTensorType([\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m6\u001b[39m]))]\n\u001b[0;32m----> 5\u001b[0m onx \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_sklearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs/rf.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      7\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(onx\u001b[38;5;241m.\u001b[39mSerializeToString())\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/skl2onnx/convert.py:118\u001b[0m, in \u001b[0;36mconvert_sklearn\u001b[0;34m(model, name, initial_types, doc_string, target_opset, custom_conversion_functions, custom_shape_calculators, custom_parsers, options, intermediate)\u001b[0m\n\u001b[1;32m    114\u001b[0m target_opset \u001b[38;5;241m=\u001b[39m (target_opset\n\u001b[1;32m    115\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m target_opset \u001b[38;5;28;01melse\u001b[39;00m get_opset_number_from_onnx())\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Parse scikit-learn model as our internal data structure\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# (i.e., Topology)\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m topology \u001b[38;5;241m=\u001b[39m \u001b[43mparse_sklearn_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_opset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mcustom_conversion_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mcustom_shape_calculators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_parsers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;66;03m# Infer variable shapes\u001b[39;00m\n\u001b[1;32m    123\u001b[0m topology\u001b[38;5;241m.\u001b[39mcompile()\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/skl2onnx/_parse.py:320\u001b[0m, in \u001b[0;36mparse_sklearn_model\u001b[0;34m(model, initial_types, target_opset, custom_conversion_functions, custom_shape_calculators, custom_parsers)\u001b[0m\n\u001b[1;32m    317\u001b[0m     raw_model_container\u001b[38;5;241m.\u001b[39madd_input(variable)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;66;03m# Parse the input scikit-learn model as a Topology object.\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mparse_sklearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcustom_parsers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_parsers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m# The object raw_model_container is a part of the topology we're\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;66;03m# going to return. We use it to store the outputs of the\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;66;03m# scikit-learn's computational graph.\u001b[39;00m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m outputs:\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/skl2onnx/_parse.py:259\u001b[0m, in \u001b[0;36mparse_sklearn\u001b[0;34m(scope, model, inputs, custom_parsers)\u001b[0m\n\u001b[1;32m    256\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m custom_parsers[tmodel](scope, model, inputs,\n\u001b[1;32m    257\u001b[0m                                      custom_parsers\u001b[38;5;241m=\u001b[39mcustom_parsers)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m tmodel \u001b[38;5;129;01min\u001b[39;00m sklearn_parsers_map:\n\u001b[0;32m--> 259\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43msklearn_parsers_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtmodel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mcustom_parsers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_parsers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    262\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m _parse_sklearn_simple_model(scope, model, inputs,\n\u001b[1;32m    263\u001b[0m                                           custom_parsers\u001b[38;5;241m=\u001b[39mcustom_parsers)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/skl2onnx/_parse.py:216\u001b[0m, in \u001b[0;36m_parse_sklearn_classifier\u001b[0;34m(scope, model, inputs, custom_parsers)\u001b[0m\n\u001b[1;32m    214\u001b[0m this_operator \u001b[38;5;241m=\u001b[39m scope\u001b[38;5;241m.\u001b[39mdeclare_local_operator(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSklearnZipMap\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    215\u001b[0m this_operator\u001b[38;5;241m.\u001b[39minputs \u001b[38;5;241m=\u001b[39m probability_tensor\n\u001b[0;32m--> 216\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\n\u001b[1;32m    217\u001b[0m label_type \u001b[38;5;241m=\u001b[39m Int64Type()\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(model\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mfloating):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'classes_'"
     ]
    }
   ],
   "source": [
    "# Convert into RF model into ONNX format file\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "initial_type = [('float_input', FloatTensorType([None, 6]))]\n",
    "onx = convert_sklearn(rf, initial_types=initial_type)\n",
    "with open(\"outputs/rf.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model Registering Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model support-vector-classifier\n",
      "Name: support-vector-classifier\n",
      "Version: 1\n"
     ]
    }
   ],
   "source": [
    "# Register Model on AzureML WS\n",
    "model = Model.register(model_path = './outputs/svc.onnx', # this points to a local file \n",
    "                       model_name = \"support-vector-classifier\", # this is the name the model is registered as\n",
    "                       tags = {'dataset': dataset.name, 'version': dataset.version, 'hyparameter-C': '1', 'testdata-accuracy': '0.9519'}, \n",
    "                       model_framework='pandas==0.23.4',\n",
    "                       description = \"Support vector classifier to predict weather at port of Turku\",\n",
    "                       workspace = workspace)\n",
    "\n",
    "print('Name:', model.name)\n",
    "print('Version:', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading svc.onnx\u001b[32m (< 1 MB): 100%|██████████| 272k/272k [00:00<00:00, 7.08MB/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model({'job_name': None, 'is_anonymous': False, 'auto_increment_version': False, 'name': 'support-vector-classifier', 'description': 'Support vector classifier to predict weather at port of Turku', 'tags': {}, 'properties': {}, 'id': '/subscriptions/4a571c1c-a483-4a43-9930-490479d70db0/resourceGroups/Learn_MLOps/providers/Microsoft.MachineLearningServices/workspaces/MLOs_WS/models/support-vector-classifier/versions/1', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/eddyhakz1/code/Learn_Mlops/04_ML_Pipelines', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fda13bef310>, 'serialize': <msrest.serialization.Serializer object at 0x7fda18102f10>, 'version': '1', 'latest_version': None, 'path': 'azureml://subscriptions/4a571c1c-a483-4a43-9930-490479d70db0/resourceGroups/Learn_MLOps/workspaces/MLOs_WS/datastores/workspaceblobstore/paths/LocalUpload/1b3639d318948f811f52d534dc56cb04/svc.onnx', 'datastore': None, 'utc_time_created': None, 'flavors': None, 'arm_type': 'model_version', 'type': 'custom_model'})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "file_model = Model(\n",
    "    path=\"./outputs/svc.onnx\",\n",
    "    type=AssetTypes.CUSTOM_MODEL,\n",
    "    name=\"support-vector-classifier\",\n",
    "    description=\"Support vector classifier to predict weather at port of Turku\"\n",
    ")\n",
    "ml_client.models.create_or_update(file_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model random-forest-classifier\n",
      "Name: random-forest-classifier\n",
      "Version: 1\n"
     ]
    }
   ],
   "source": [
    "# Register Model on AzureML WS\n",
    "model = Model.register(model_path = './outputs/rf.onnx', # this points to a local file \n",
    "                       model_name = \"random-forest-classifier\", # this is the name the model is registered as\n",
    "                       tags = {'dataset': dataset.name, 'version': dataset.version, 'hyparameter-C': '1', 'testdata-accuracy': '0.9548'}, \n",
    "                       model_framework='pandas==0.23.4',\n",
    "                       description = \"Random forest classifier to predict weather at port of Turku\",\n",
    "                       workspace = workspace)\n",
    "\n",
    "print('Name:', model.name)\n",
    "print('Version:', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020/08/11 10:59:46 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under azureml://experiments/mlflow-random-forest-classifier/runs/f1f99844-efc2-4e48-bced-53c205fb5543/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the  tracking store. If logging to a mlflow server via REST, consider  upgrading the server version to MLflow 1.7.0 or above.\n"
     ]
    }
   ],
   "source": [
    "# Save the model to the outputs directory for capture\n",
    "mlflow.sklearn.log_model(svc, 'outputs/svc.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020/08/11 11:00:21 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under azureml://experiments/mlflow-random-forest-classifier/runs/f1f99844-efc2-4e48-bced-53c205fb5543/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the  tracking store. If logging to a mlflow server via REST, consider  upgrading the server version to MLflow 1.7.0 or above.\n"
     ]
    }
   ],
   "source": [
    "# Save the model to the outputs directory for capture\n",
    "mlflow.sklearn.log_model(rf, 'outputs/rf.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model artefacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./outputs/scaler.pkl', 'wb') as scaler_pkl:\n",
    "    pickle.dump(sc, scaler_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading scaler.pkl\u001b[32m (< 1 MB): 100%|██████████| 599/599 [00:00<00:00, 48.1kB/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Model({'job_name': None, 'is_anonymous': False, 'auto_increment_version': False, 'name': 'scaler', 'description': 'Scaler used for scaling incoming inference data', 'tags': {}, 'properties': {}, 'id': '/subscriptions/4a571c1c-a483-4a43-9930-490479d70db0/resourceGroups/Learn_MLOps/providers/Microsoft.MachineLearningServices/workspaces/MLOs_WS/models/scaler/versions/1', 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/eddyhakz1/code/Learn_Mlops/04_ML_Pipelines', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fda187eb760>, 'serialize': <msrest.serialization.Serializer object at 0x7fda18104bb0>, 'version': '1', 'latest_version': None, 'path': 'azureml://subscriptions/4a571c1c-a483-4a43-9930-490479d70db0/resourceGroups/Learn_MLOps/workspaces/MLOs_WS/datastores/workspaceblobstore/paths/LocalUpload/942322bf58670231c40d8ce7d3440d00/scaler.pkl', 'datastore': None, 'utc_time_created': None, 'flavors': None, 'arm_type': 'model_version', 'type': 'custom_model'})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "file_model = Model(\n",
    "    path=\"./outputs/scaler.pkl\",\n",
    "    type=AssetTypes.CUSTOM_MODEL,\n",
    "    name=\"scaler\",\n",
    "    description=\"Scaler used for scaling incoming inference data\",\n",
    ")\n",
    "ml_client.models.create_or_update(file_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
