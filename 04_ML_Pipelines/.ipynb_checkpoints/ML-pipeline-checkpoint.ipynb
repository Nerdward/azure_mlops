{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from math import sqrt\n",
    "warnings.filterwarnings('ignore')\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import mlflow\n",
    "import mltable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "subscription_id = '4a571c1c-a483-4a43-9930-490479d70db0'\n",
    "resource_group = 'Learn_MLOps'\n",
    "workspace_name = 'MLOs_WS'\n",
    "\n",
    "workspace = Workspace(subscription_id, resource_group, workspace_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-ai-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Enter details of your AML workspace\n",
    "subscription_id = \"4a571c1c-a483-4a43-9930-490479d70db0\"\n",
    "resource_group = \"Learn_MLOps\"\n",
    "workspace = \"MLOs_WS\"\n",
    "\n",
    "# get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_data_asset = ml_client.data.get(\n",
    "    name=\"processed_weather_data_port_of_Turku\",version='1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get_mlflow_tracking_uri'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m uri \u001b[38;5;241m=\u001b[39m \u001b[43mworkspace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_mlflow_tracking_uri\u001b[49m()\n\u001b[1;32m      2\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mset_tracking_uri(uri)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get_mlflow_tracking_uri'"
     ]
    }
   ],
   "source": [
    "uri = workspace.get_mlflow_tracking_uri()\n",
    "mlflow.set_tracking_uri(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Location</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind_speed_kmph</th>\n",
       "      <th>Wind_bearing_degrees</th>\n",
       "      <th>Visibility_km</th>\n",
       "      <th>Pressure_millibars</th>\n",
       "      <th>Current_weather_condition</th>\n",
       "      <th>Future_weather_condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-04-01 04:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>8.755555556</td>\n",
       "      <td>0.83</td>\n",
       "      <td>11.0446</td>\n",
       "      <td>259</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>1016.51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-04-01 05:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>9.222222222</td>\n",
       "      <td>0.85</td>\n",
       "      <td>13.9587</td>\n",
       "      <td>258</td>\n",
       "      <td>14.9569</td>\n",
       "      <td>1016.66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-04-01 06:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>7.733333333</td>\n",
       "      <td>0.95</td>\n",
       "      <td>12.3648</td>\n",
       "      <td>259</td>\n",
       "      <td>9.982</td>\n",
       "      <td>1016.72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-04-01 07:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>8.772222222</td>\n",
       "      <td>0.89</td>\n",
       "      <td>14.1519</td>\n",
       "      <td>260</td>\n",
       "      <td>9.982</td>\n",
       "      <td>1016.84</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-04-01 08:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>10.82222222</td>\n",
       "      <td>0.82</td>\n",
       "      <td>11.3183</td>\n",
       "      <td>259</td>\n",
       "      <td>9.982</td>\n",
       "      <td>1017.37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Timestamp                Location Temperature_C Humidity  \\\n",
       "0  2006-04-01 04:00:00+02:00  Port of Turku, Finland   8.755555556     0.83   \n",
       "1  2006-04-01 05:00:00+02:00  Port of Turku, Finland   9.222222222     0.85   \n",
       "2  2006-04-01 06:00:00+02:00  Port of Turku, Finland   7.733333333     0.95   \n",
       "3  2006-04-01 07:00:00+02:00  Port of Turku, Finland   8.772222222     0.89   \n",
       "4  2006-04-01 08:00:00+02:00  Port of Turku, Finland   10.82222222     0.82   \n",
       "\n",
       "  Wind_speed_kmph Wind_bearing_degrees Visibility_km Pressure_millibars  \\\n",
       "0         11.0446                  259       15.8263            1016.51   \n",
       "1         13.9587                  258       14.9569            1016.66   \n",
       "2         12.3648                  259         9.982            1016.72   \n",
       "3         14.1519                  260         9.982            1016.84   \n",
       "4         11.3183                  259         9.982            1017.37   \n",
       "\n",
       "  Current_weather_condition Future_weather_condition  \n",
       "0                         1                        1  \n",
       "1                         1                        1  \n",
       "2                         1                        1  \n",
       "3                         1                        1  \n",
       "4                         1                        1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a path or folder or pattern\n",
    "# path = {\n",
    "#     'file': 'azureml://subscriptions/4a571c1c-a483-4a43-9930-490479d70db0/resourcegroups/Learn_MLops/workspaces/MLOs_WS/datastores/workspaceblobstore/paths/LocalUpload/39e72abce50cc70e7c0f6e2cdab79e0b/Dataset/weather_dataset_processed.csv'}\n",
    "\n",
    "path = {'file':f'{registered_data_asset.path}weather_dataset_processed.csv'}\n",
    "# create an mltable from paths\n",
    "tbl = mltable.from_delimited_files(paths=[path])\n",
    "\n",
    "# materialize to pandas\n",
    "df = tbl.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Location</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind_speed_kmph</th>\n",
       "      <th>Wind_bearing_degrees</th>\n",
       "      <th>Visibility_km</th>\n",
       "      <th>Pressure_millibars</th>\n",
       "      <th>Current_weather_condition</th>\n",
       "      <th>Future_weather_condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-04-01 04:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>8.755555556</td>\n",
       "      <td>0.83</td>\n",
       "      <td>11.0446</td>\n",
       "      <td>259</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>1016.51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-04-01 05:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>9.222222222</td>\n",
       "      <td>0.85</td>\n",
       "      <td>13.9587</td>\n",
       "      <td>258</td>\n",
       "      <td>14.9569</td>\n",
       "      <td>1016.66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-04-01 06:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>7.733333333</td>\n",
       "      <td>0.95</td>\n",
       "      <td>12.3648</td>\n",
       "      <td>259</td>\n",
       "      <td>9.982</td>\n",
       "      <td>1016.72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-04-01 07:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>8.772222222</td>\n",
       "      <td>0.89</td>\n",
       "      <td>14.1519</td>\n",
       "      <td>260</td>\n",
       "      <td>9.982</td>\n",
       "      <td>1016.84</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-04-01 08:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>10.82222222</td>\n",
       "      <td>0.82</td>\n",
       "      <td>11.3183</td>\n",
       "      <td>259</td>\n",
       "      <td>9.982</td>\n",
       "      <td>1017.37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Timestamp                Location Temperature_C Humidity  \\\n",
       "0  2006-04-01 04:00:00+02:00  Port of Turku, Finland   8.755555556     0.83   \n",
       "1  2006-04-01 05:00:00+02:00  Port of Turku, Finland   9.222222222     0.85   \n",
       "2  2006-04-01 06:00:00+02:00  Port of Turku, Finland   7.733333333     0.95   \n",
       "3  2006-04-01 07:00:00+02:00  Port of Turku, Finland   8.772222222     0.89   \n",
       "4  2006-04-01 08:00:00+02:00  Port of Turku, Finland   10.82222222     0.82   \n",
       "\n",
       "  Wind_speed_kmph Wind_bearing_degrees Visibility_km Pressure_millibars  \\\n",
       "0         11.0446                  259       15.8263            1016.51   \n",
       "1         13.9587                  258       14.9569            1016.66   \n",
       "2         12.3648                  259         9.982            1016.72   \n",
       "3         14.1519                  260         9.982            1016.84   \n",
       "4         11.3183                  259         9.982            1017.37   \n",
       "\n",
       "  Current_weather_condition Future_weather_condition  \n",
       "0                         1                        1  \n",
       "1                         1                        1  \n",
       "2                         1                        1  \n",
       "3                         1                        1  \n",
       "4                         1                        1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting Pre-Processed data into Training and Validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set is used later to evaluate model performance post training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = df.iloc[:77160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77160, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = df.drop(df_training.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19289, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Registering Training and Validation data to the datastore on the workspace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.to_csv('Data/training_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation.to_csv('Data/validation_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "# Supported paths include:\n",
    "# local: './<path>'\n",
    "# blob:  'https://<account_name>.blob.core.windows.net/<container_name>/<path>'\n",
    "# ADLS gen2: 'abfss://<file_system>@<account_name>.dfs.core.windows.net/<path>/'\n",
    "# Datastore: 'azureml://datastores/<data_store_name>/paths/<path>'\n",
    "\n",
    "my_path = './Data/'\n",
    "\n",
    "my_data = Data(\n",
    "    path=my_path,\n",
    "    type=AssetTypes.MLTABLE,\n",
    "    description='processed weather data',\n",
    "    name=\"processed_weather_data_port_of_Turku\",\n",
    "    version='2'\n",
    ")\n",
    "\n",
    "ml_client.data.create_or_update(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data ingestion step - Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = {'file':'azureml://subscriptions/4a571c1c-a483-4a43-9930-490479d70db0/resourcegroups/Learn_MLops/workspaces/MLOs_WS/datastores/workspaceblobstore/paths/LocalUpload/2ee72d117bfcc8b45d53e4ba082b4d2a/Data/training_data.csv'}\n",
    "# create an mltable from paths\n",
    "tbl = mltable.from_delimited_files(paths=[path])\n",
    "\n",
    "# materialize to pandas\n",
    "df = tbl.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Location</th>\n",
       "      <th>Temperature_C</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind_speed_kmph</th>\n",
       "      <th>Wind_bearing_degrees</th>\n",
       "      <th>Visibility_km</th>\n",
       "      <th>Pressure_millibars</th>\n",
       "      <th>Current_weather_condition</th>\n",
       "      <th>Future_weather_condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-04-01 04:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>8.755555556</td>\n",
       "      <td>0.83</td>\n",
       "      <td>11.0446</td>\n",
       "      <td>259</td>\n",
       "      <td>15.8263</td>\n",
       "      <td>1016.51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-04-01 05:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>9.222222222</td>\n",
       "      <td>0.85</td>\n",
       "      <td>13.9587</td>\n",
       "      <td>258</td>\n",
       "      <td>14.9569</td>\n",
       "      <td>1016.66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-04-01 06:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>7.733333333</td>\n",
       "      <td>0.95</td>\n",
       "      <td>12.3648</td>\n",
       "      <td>259</td>\n",
       "      <td>9.982</td>\n",
       "      <td>1016.72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-04-01 07:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>8.772222222</td>\n",
       "      <td>0.89</td>\n",
       "      <td>14.1519</td>\n",
       "      <td>260</td>\n",
       "      <td>9.982</td>\n",
       "      <td>1016.84</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-04-01 08:00:00+02:00</td>\n",
       "      <td>Port of Turku, Finland</td>\n",
       "      <td>10.82222222</td>\n",
       "      <td>0.82</td>\n",
       "      <td>11.3183</td>\n",
       "      <td>259</td>\n",
       "      <td>9.982</td>\n",
       "      <td>1017.37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Timestamp                Location Temperature_C Humidity  \\\n",
       "0  2006-04-01 04:00:00+02:00  Port of Turku, Finland   8.755555556     0.83   \n",
       "1  2006-04-01 05:00:00+02:00  Port of Turku, Finland   9.222222222     0.85   \n",
       "2  2006-04-01 06:00:00+02:00  Port of Turku, Finland   7.733333333     0.95   \n",
       "3  2006-04-01 07:00:00+02:00  Port of Turku, Finland   8.772222222     0.89   \n",
       "4  2006-04-01 08:00:00+02:00  Port of Turku, Finland   10.82222222     0.82   \n",
       "\n",
       "  Wind_speed_kmph Wind_bearing_degrees Visibility_km Pressure_millibars  \\\n",
       "0         11.0446                  259       15.8263            1016.51   \n",
       "1         13.9587                  258       14.9569            1016.66   \n",
       "2         12.3648                  259         9.982            1016.72   \n",
       "3         14.1519                  260         9.982            1016.84   \n",
       "4         11.3183                  259         9.982            1017.37   \n",
       "\n",
       "  Current_weather_condition Future_weather_condition  \n",
       "0                         1                        1  \n",
       "1                         1                        1  \n",
       "2                         1                        1  \n",
       "3                         1                        1  \n",
       "4                         1                        1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77160, 10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '1', '1', ..., '1', '1', '1'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['Temperature_C', 'Humidity', 'Wind_speed_kmph', 'Wind_bearing_degrees', 'Visibility_km', 'Pressure_millibars', 'Current_weather_condition']].values\n",
    "y = df['Future_weather_condition'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.7 MB)\n",
      "     |████████████████████████████████| 9.7 MB 6.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=1.3.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-learn) (1.21.6)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from scikit-learn) (2.2.0)\n",
      "Collecting joblib>=1.1.1\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     |████████████████████████████████| 297 kB 94.2 MB/s eta 0:00:01\n",
      "ERROR: pyldavis 3.3.1 requires sklearn, which is not installed.\n",
      "ERROR: responsibleai 0.22.0 has requirement ipykernel<=6.6.0, but you'll have ipykernel 6.8.0 which is incompatible.\n",
      "ERROR: responsibleai 0.22.0 has requirement numba<0.54.0, but you'll have numba 0.55.2 which is incompatible.\n",
      "ERROR: responsibleai 0.22.0 has requirement scikit-learn<1.1,>=0.22.1, but you'll have scikit-learn 1.2.0 which is incompatible.\n",
      "ERROR: raiwidgets 0.22.0 has requirement itsdangerous==2.0.1, but you'll have itsdangerous 2.1.2 which is incompatible.\n",
      "ERROR: pyldavis 3.3.1 has requirement pandas>=1.2.0, but you'll have pandas 1.1.5 which is incompatible.\n",
      "ERROR: pycaret 2.3.10 has requirement numba<0.55, but you'll have numba 0.55.2 which is incompatible.\n",
      "ERROR: pycaret 2.3.10 has requirement pyyaml<6.0.0, but you'll have pyyaml 6.0 which is incompatible.\n",
      "ERROR: pycaret 2.3.10 has requirement scikit-learn==0.23.2, but you'll have scikit-learn 1.2.0 which is incompatible.\n",
      "ERROR: pandas-profiling 3.4.0 has requirement statsmodels<0.14,>=0.13.2, but you'll have statsmodels 0.11.0 which is incompatible.\n",
      "ERROR: econml 0.13.1 has requirement scikit-learn<1.2,>0.22.0, but you'll have scikit-learn 1.2.0 which is incompatible.\n",
      "ERROR: azureml-training-tabular 1.47.0 has requirement joblib==0.14.1, but you'll have joblib 1.2.0 which is incompatible.\n",
      "ERROR: azureml-training-tabular 1.47.0 has requirement scikit-learn<0.23.0,>=0.19.0, but you'll have scikit-learn 1.2.0 which is incompatible.\n",
      "ERROR: azureml-train-automl-runtime 1.47.0 has requirement scikit-learn<0.23.0,>=0.19.0, but you'll have scikit-learn 1.2.0 which is incompatible.\n",
      "ERROR: azureml-automl-runtime 1.47.0 has requirement joblib==0.14.1, but you'll have joblib 1.2.0 which is incompatible.\n",
      "ERROR: azureml-automl-runtime 1.47.0 has requirement scikit-learn<0.23.0,>=0.19.0, but you'll have scikit-learn 1.2.0 which is incompatible.\n",
      "ERROR: autokeras 1.0.16 has requirement tensorflow<=2.5.0,>=2.3.0, but you'll have tensorflow 2.2.1 which is incompatible.\n",
      "\u001b[?25hInstalling collected packages: joblib, scikit-learn\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 0.14.1\n",
      "    Uninstalling joblib-0.14.1:\n",
      "      Successfully uninstalled joblib-0.14.1\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.22.1\n",
      "    Uninstalling scikit-learn-0.22.1:\n",
      "      Successfully uninstalled scikit-learn-0.22.1\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Splitting the Training dataset into Train and Test set for ML training\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m----> 3\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mX\u001b[49m, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Splitting the Training dataset into Train and Test set for ML training\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m      2\u001b[0m sc \u001b[38;5;241m=\u001b[39m StandardScaler()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and Testing Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "myexperiment = Experiment(workspace, \"support-vector-machine\")\n",
    "mlflow.set_experiment(\"mlflow-support-vector-machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.svm import SVC\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a run in Azureml and mlflow experiments\n",
    "run = myexperiment.start_logging()\n",
    "mlflow.start_run()\n",
    "\n",
    "\n",
    "run.log(\"dataset name\", dataset.name)\n",
    "run.log(\"dataset Version\", dataset.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_grid = GridSearchCV(svc, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 40s, sys: 1.71 s, total: 6min 41s\n",
      "Wall time: 6min 45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'kernel': ('linear', 'rbf'), 'C': [1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svc_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': 'warn',\n",
       " 'error_score': 'raise-deprecating',\n",
       " 'estimator__C': 1.0,\n",
       " 'estimator__cache_size': 200,\n",
       " 'estimator__class_weight': None,\n",
       " 'estimator__coef0': 0.0,\n",
       " 'estimator__decision_function_shape': 'ovr',\n",
       " 'estimator__degree': 3,\n",
       " 'estimator__gamma': 'auto_deprecated',\n",
       " 'estimator__kernel': 'rbf',\n",
       " 'estimator__max_iter': -1,\n",
       " 'estimator__probability': False,\n",
       " 'estimator__random_state': None,\n",
       " 'estimator__shrinking': True,\n",
       " 'estimator__tol': 0.001,\n",
       " 'estimator__verbose': False,\n",
       " 'estimator': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "   kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "   shrinking=True, tol=0.001, verbose=False),\n",
       " 'fit_params': None,\n",
       " 'iid': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'param_grid': {'kernel': ('linear', 'rbf'), 'C': [1, 10]},\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'return_train_score': 'warn',\n",
       " 'scoring': None,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_grid.get_params(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=svc_grid.get_params(deep=True)['estimator__C'], kernel=svc_grid.get_params(deep=True)['estimator__kernel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging training parameters to AzureML and MLFlow experiments\n",
    "run.log(\"C\", svc_grid.get_params(deep=True)['estimator__C'])\n",
    "run.log(\"Kernel\", svc_grid.get_params(deep=True)['estimator__kernel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_svc = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, predicted_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "fscore = f1_score(y_test, predicted_svc, average=\"macro\")\n",
    "precision = precision_score(y_test, predicted_svc, average=\"macro\")\n",
    "recall = recall_score(y_test, predicted_svc, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "repo = git.Repo(search_parent_directories=True)\n",
    "sha = repo.head.object.hexsha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log to AzureML and MLflow\n",
    "run.log(\"Test_accuracy\", acc)\n",
    "run.log(\"Precision\", precision)\n",
    "run.log(\"Recall\", recall)\n",
    "run.log(\"F-Score\", fscore)\n",
    "run.log(\"Git-sha\", sha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id: 5f2d4100-19aa-4ddc-9bf5-402117da8c77\n"
     ]
    }
   ],
   "source": [
    "run.complete()\n",
    "print (\"run id:\", run.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset name': 'training_dataset',\n",
       " 'dataset Version': 1,\n",
       " 'C': 1.0,\n",
       " 'Kernel': 'rbf',\n",
       " 'Test_accuracy': 0.9519180922757906,\n",
       " 'Precision': 0.8869828453699851,\n",
       " 'Recall': 0.8859050416892464,\n",
       " 'F-Score': 0.8864428755463128,\n",
       " 'Git-sha': 'bb282af9afe9422cb0986c873bf881e1c994e580'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '/subscriptions/6faa9ede-4786-48dc-9c1e-0262e2844ebf/resourceGroups/Learn_MLOps/providers/Microsoft.MachineLearningServices/workspaces/MLOps_WS',\n",
       " 'name': 'MLOps_WS',\n",
       " 'location': 'northeurope',\n",
       " 'type': 'Microsoft.MachineLearningServices/workspaces',\n",
       " 'tags': {},\n",
       " 'sku': 'Basic',\n",
       " 'workspaceid': 'e8674bfa-cb69-4989-8a02-de19862bbbd0',\n",
       " 'description': '',\n",
       " 'friendlyName': 'MLOps_WS',\n",
       " 'creationTime': '2020-07-29T05:13:13.4348343+00:00',\n",
       " 'keyVault': '/subscriptions/6faa9ede-4786-48dc-9c1e-0262e2844ebf/resourcegroups/learn_mlops/providers/microsoft.keyvault/vaults/mlopsws6106784693',\n",
       " 'applicationInsights': '/subscriptions/6faa9ede-4786-48dc-9c1e-0262e2844ebf/resourcegroups/learn_mlops/providers/microsoft.insights/components/mlopsws8072806275',\n",
       " 'identityPrincipalId': '4f27e823-96d9-4f95-8782-8f5a34535ad1',\n",
       " 'identityTenantId': 'd22095da-de0a-479f-adc4-47380feb19a1',\n",
       " 'identityType': 'SystemAssigned',\n",
       " 'storageAccount': '/subscriptions/6faa9ede-4786-48dc-9c1e-0262e2844ebf/resourcegroups/learn_mlops/providers/microsoft.storage/storageaccounts/mlopsws3826143660',\n",
       " 'hbiWorkspace': False,\n",
       " 'discoveryUrl': 'https://northeurope.experiments.azureml.net/discovery',\n",
       " 'notebookInfo': {'fqdn': 'ml-mlops_ws-northeurope-e8674bfa-cb69-4989-8a02-de19862bbbd0.notebooks.azure.net',\n",
       "  'resource_id': 'd1a408e9631e4ecea24ff63427e37e94'}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspace.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020/08/11 06:20:19 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under azureml://experiments/support-vector-machine/runs/9a99e035-1323-4ebf-87c9-98d8548fce05/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the  tracking store. If logging to a mlflow server via REST, consider  upgrading the server version to MLflow 1.7.0 or above.\n"
     ]
    }
   ],
   "source": [
    "import mlflow.sklearn\n",
    "mlflow.sklearn.log_model(svc, 'outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "myexperiment = Experiment(workspace, \"random-forest-classifier\")\n",
    "mlflow.set_experiment(\"mlflow-random-forest-classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=10, random_state=0, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize runs in Azureml and mlflow\n",
    "run = myexperiment.start_logging()\n",
    "mlflow.start_run()\n",
    "\n",
    "\n",
    "# Log dataset used \n",
    "run.log(\"dataset name\", dataset.name)\n",
    "run.log(\"dataset Version\", dataset.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.52 s, sys: 3.97 ms, total: 6.52 s\n",
      "Wall time: 6.59 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging training parameters to AzureML and MLFlow experiments\n",
    "run.log(\"max_depth\", 10)\n",
    "run.log(\"random_state\", 0)\n",
    "run.log(\"n_estimators\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, predicted_rf)\n",
    "fscore = f1_score(y_test, predicted_rf, average=\"macro\")\n",
    "precision = precision_score(y_test, predicted_rf, average=\"macro\")\n",
    "recall = recall_score(y_test, predicted_rf, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log(\"Test_accuracy\", acc)\n",
    "run.log(\"Precision\", precision)\n",
    "run.log(\"Recall\", recall)\n",
    "run.log(\"F-Score\", fscore)\n",
    "run.log(\"Git-sha\", sha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id: 5596d473-fa15-4925-ab9b-8155845b560b\n"
     ]
    }
   ],
   "source": [
    "run.complete()\n",
    "print (\"run id:\", run.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset name': 'training_dataset',\n",
       " 'dataset Version': 1,\n",
       " 'max_depth': 10,\n",
       " 'n_estimators': 100,\n",
       " 'random_state': 0,\n",
       " 'Test_accuracy': 0.9548989113530326,\n",
       " 'Precision': 0.9018705246237031,\n",
       " 'Recall': 0.8804084310202218,\n",
       " 'F-Score': 0.8907272822498857,\n",
       " 'Git-sha': 'bb282af9afe9422cb0986c873bf881e1c994e580'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Packaging Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pickle file or onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - The maximum opset needed by this model is only 1.\n"
     ]
    }
   ],
   "source": [
    "# Convert into SVC model into ONNX format file\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "initial_type = [('float_input', FloatTensorType([None, 6]))]\n",
    "onx = convert_sklearn(svc, initial_types=initial_type)\n",
    "with open(\"outputs/svc.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - The maximum opset needed by this model is only 1.\n",
      "WARNING - The maximum opset needed by this model is only 9.\n"
     ]
    }
   ],
   "source": [
    "# Convert into RF model into ONNX format file\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "initial_type = [('float_input', FloatTensorType([None, 6]))]\n",
    "onx = convert_sklearn(rf, initial_types=initial_type)\n",
    "with open(\"outputs/rf.onnx\", \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Registering Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model support-vector-classifier\n",
      "Name: support-vector-classifier\n",
      "Version: 1\n"
     ]
    }
   ],
   "source": [
    "# Register Model on AzureML WS\n",
    "model = Model.register(model_path = './outputs/svc.onnx', # this points to a local file \n",
    "                       model_name = \"support-vector-classifier\", # this is the name the model is registered as\n",
    "                       tags = {'dataset': dataset.name, 'version': dataset.version, 'hyparameter-C': '1', 'testdata-accuracy': '0.9519'}, \n",
    "                       model_framework='pandas==0.23.4',\n",
    "                       description = \"Support vector classifier to predict weather at port of Turku\",\n",
    "                       workspace = workspace)\n",
    "\n",
    "print('Name:', model.name)\n",
    "print('Version:', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model random-forest-classifier\n",
      "Name: random-forest-classifier\n",
      "Version: 1\n"
     ]
    }
   ],
   "source": [
    "# Register Model on AzureML WS\n",
    "model = Model.register(model_path = './outputs/rf.onnx', # this points to a local file \n",
    "                       model_name = \"random-forest-classifier\", # this is the name the model is registered as\n",
    "                       tags = {'dataset': dataset.name, 'version': dataset.version, 'hyparameter-C': '1', 'testdata-accuracy': '0.9548'}, \n",
    "                       model_framework='pandas==0.23.4',\n",
    "                       description = \"Random forest classifier to predict weather at port of Turku\",\n",
    "                       workspace = workspace)\n",
    "\n",
    "print('Name:', model.name)\n",
    "print('Version:', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020/08/11 10:59:46 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under azureml://experiments/mlflow-random-forest-classifier/runs/f1f99844-efc2-4e48-bced-53c205fb5543/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the  tracking store. If logging to a mlflow server via REST, consider  upgrading the server version to MLflow 1.7.0 or above.\n"
     ]
    }
   ],
   "source": [
    "# Save the model to the outputs directory for capture\n",
    "mlflow.sklearn.log_model(svc, 'outputs/svc.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020/08/11 11:00:21 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under azureml://experiments/mlflow-random-forest-classifier/runs/f1f99844-efc2-4e48-bced-53c205fb5543/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the  tracking store. If logging to a mlflow server via REST, consider  upgrading the server version to MLflow 1.7.0 or above.\n"
     ]
    }
   ],
   "source": [
    "# Save the model to the outputs directory for capture\n",
    "mlflow.sklearn.log_model(rf, 'outputs/rf.onnx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model artefacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./outputs/scaler.pkl', 'wb') as scaler_pkl:\n",
    "    pickle.dump(sc, scaler_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model scaler\n",
      "Name: scaler\n",
      "Version: 1\n"
     ]
    }
   ],
   "source": [
    "# Register Model on AzureML WS\n",
    "scaler = Model.register(model_path = './outputs/scaler.pkl', # this points to a local file \n",
    "                       model_name = \"scaler\", # this is the name the model is registered as\n",
    "                       tags = {'dataset': dataset.name, 'version': dataset.version}, \n",
    "                       model_framework='pandas==0.23.4',\n",
    "                       description = \"Scaler used for scaling incoming inference data\",\n",
    "                       workspace = workspace)\n",
    "\n",
    "print('Name:', scaler.name)\n",
    "print('Version:', scaler.version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
